
@misc{zhong_practical_2018,
	title = {Practical {Block}-wise {Neural} {Network} {Architecture} {Generation}},
	url = {http://arxiv.org/abs/1708.05552},
	abstract = {Convolutional neural networks have gained a remarkable success in computer vision. However, most usable network architectures are hand-crafted and usually require expertise and elaborate design. In this paper, we provide a block-wise network generation pipeline called BlockQNN which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy. The optimal network block is constructed by the learning agent which is trained sequentially to choose component layers. We stack the block to construct the whole auto-generated network. To accelerate the generation process, we also propose a distributed asynchronous framework and an early stop strategy. The block-wise generation brings unique advantages: (1) it performs competitive results in comparison to the hand-crafted state-of-the-art networks on image classification, additionally, the best network generated by BlockQNN achieves 3.54\% top-1 error rate on CIFAR-10 which beats all existing auto-generate networks. (2) in the meanwhile, it offers tremendous reduction of the search space in designing networks which only spends 3 days with 32 GPUs, and (3) moreover, it has strong generalizability that the network built on CIFAR also performs well on a larger-scale ImageNet dataset.},
	urldate = {2023-05-05},
	publisher = {arXiv},
	author = {Zhong, Zhao and Yan, Junjie and Wu, Wei and Shao, Jing and Liu, Cheng-Lin},
	month = may,
	year = {2018},
	note = {arXiv:1708.05552 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: Accepted to CVPR 2018},
	file = {arXiv.org Snapshot:/Users/fracapuano/Zotero/storage/ZI2R395F/Zhong et al. - 2018 - Practical Block-wise Neural Network Architecture G.html:text/html;Full Text PDF:/Users/fracapuano/Zotero/storage/7ZJWPCRW/Zhong et al. - 2018 - Practical Block-wise Neural Network Architecture G.pdf:application/pdf},
}

@article{kober_reinforcement_nodate,
	title = {Reinforcement {Learning} in {Robotics}: {A} {Survey}},
	language = {en},
	author = {Kober, Jens and Bagnell, J Andrew and Peters, Jan},
	file = {PDF:/Users/fracapuano/Zotero/storage/72PRHGKL/Kober et al. - Reinforcement Learning in Robotics A Survey.pdf:application/pdf},
}

@book{lynch_modern_2017,
	edition = {1},
	title = {Modern {Robotics}: {Mechanics}, {Planning}, and {Control}},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {978-1-316-66123-9 978-1-107-15630-2 978-1-316-60984-2},
	shorttitle = {Modern {Robotics}},
	url = {https://www.cambridge.org/core/product/identifier/9781316661239/type/book},
	abstract = {This introduction to robotics offers a distinct and unified perspective of the mechanics, planning and control of robots. Ideal for self-learning, or for courses, as it assumes only freshman-level physics, ordinary differential equations, linear algebra and a little bit of computing background. Modern Robotics presents the state-of-the-art, screw-theoretic techniques capturing the most salient physical features of a robot in an intuitive geometrical way. With numerous exercises at the end of each chapter, accompanying software written to reinforce the concepts in the book and video lectures aimed at changing the classroom experience, this is the go-to textbook for learning about this fascinating subject.},
	language = {en},
	urldate = {2025-08-25},
	publisher = {Cambridge University Press},
	author = {Lynch, Kevin M. and Park, Frank C.},
	month = may,
	year = {2017},
	doi = {10.1017/9781316661239},
	file = {PDF:/Users/fracapuano/Zotero/storage/S9E6NIQ8/Lynch and Park - 2017 - Modern Robotics Mechanics, Planning, and Control.pdf:application/pdf},
}

@misc{antonova_reinforcement_2017,
	title = {Reinforcement {Learning} for {Pivoting} {Task}},
	url = {http://arxiv.org/abs/1703.00472},
	doi = {10.48550/arXiv.1703.00472},
	abstract = {In this work we propose an approach to learn a robust policy for solving the pivoting task. Recently, several model-free continuous control algorithms were shown to learn successful policies without prior knowledge of the dynamics of the task. However, obtaining successful policies required thousands to millions of training episodes, limiting the applicability of these approaches to real hardware. We developed a training procedure that allows us to use a simple custom simulator to learn policies robust to the mismatch of simulation vs robot. In our experiments, we demonstrate that the policy learned in the simulator is able to pivot the object to the desired target angle on the real robot. We also show generalization to an object with different inertia, shape, mass and friction properties than those used during training. This result is a step towards making model-free reinforcement learning available for solving robotics tasks via pre-training in simulators that offer only an imprecise match to the real-world dynamics.},
	urldate = {2025-08-25},
	publisher = {arXiv},
	author = {Antonova, Rika and Cruciani, Silvia and Smith, Christian and Kragic, Danica},
	month = mar,
	year = {2017},
	note = {arXiv:1703.00472 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
	annote = {Comment: (Rika Antonova and Silvia Cruciani contributed equally)},
	file = {Full Text PDF:/Users/fracapuano/Zotero/storage/WRZCHVGB/Antonova et al. - 2017 - Reinforcement Learning for Pivoting Task.pdf:application/pdf;Snapshot:/Users/fracapuano/Zotero/storage/WJEJ2VGU/1703.html:text/html},
}

@misc{noauthor_state_nodate,
	title = {The {State} of {Robot} {Motion} {Generation}},
	url = {https://arxiv.org/html/2410.12172v1},
	urldate = {2025-08-25},
}
