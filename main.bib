@article{agrawalComputationalSensorimotorLearning,
  title = {Computational {{Sensorimotor Learning}}},
  author = {Agrawal, Pulkit},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/KSDX9GA2/Agrawal - Computational Sensorimotor Learning.pdf}
}

@article{aldacoALOHA2Enhanced,
  title = {{{ALOHA}} 2: {{An Enhanced Low-Cost Hardware}} for {{Bimanual Teleoperation}}},
  author = {Aldaco, Jorge and Armstrong, Travis and Baruch, Robert and Bingham, Jeff and Chan, Sanky and Dwibedi, Debidatta and Finn, Chelsea and Florence, Pete and Goodrich, Spencer and Gramlich, Wayne and Herzog, Alexander and Hoech, Jonathan and Nguyen, Thinh and Storz, Ian and Tabanpour, Baruch and Tompson, Jonathan and Wahid, Ayzaan and Wahrburg, Ted and Xu, Sichun and Yaroshenko, Sergey and Zhao, Tony Z},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/LDEJG62Q/Aldaco et al. - ALOHA 2 An Enhanced Low-Cost Hardware for Bimanual Teleoperation.pdf}
}

@article{alizadehComprehensiveSurveySpace2024,
  title = {A Comprehensive Survey of Space Robotic Manipulators for On-Orbit Servicing},
  author = {Alizadeh, Mohammad and Zhu, Zheng H.},
  year = {2024},
  month = oct,
  journal = {Frontiers in Robotics and AI},
  volume = {11},
  publisher = {Frontiers},
  issn = {2296-9144},
  doi = {10.3389/frobt.2024.1470950},
  urldate = {2025-08-26},
  abstract = {On-Orbit Servicing (OOS) robots are transforming space exploration by enabling vital maintenance and repair of spacecraft directly in space. However, achieving precise and safe manipulation in microgravity necessitates overcoming significant challenges. This survey delves into four crucial areas essential for successful OOS manipulation: object state estimation, motion planning, and feedback control. Techniques from traditional vision to advanced X-ray and neural network methods are explored for object state estimation. Strategies for fuel-optimized trajectories, docking maneuvers, and collision avoidance are examined in motion planning. The survey also explores control methods for various scenarios, including cooperative manipulation and handling uncertainties, in feedback control. Additionally, this survey examines how Machine learning techniques can further propel OOS robots towards more complex and delicate tasks in space.},
  langid = {english},
  keywords = {control,machine learning,motion planning,on-orbit servicing,pose estimation,robotic manipulator,space robots},
  file = {/Users/fracapuano/Zotero/storage/VA36KZYY/Alizadeh and Zhu - 2024 - A comprehensive survey of space robotic manipulators for on-orbit servicing.pdf}
}

@misc{antonovaReinforcementLearningPivoting2017,
  title = {Reinforcement {{Learning}} for {{Pivoting Task}}},
  author = {Antonova, Rika and Cruciani, Silvia and Smith, Christian and Kragic, Danica},
  year = {2017},
  month = mar,
  number = {arXiv:1703.00472},
  eprint = {1703.00472},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1703.00472},
  urldate = {2025-08-25},
  abstract = {In this work we propose an approach to learn a robust policy for solving the pivoting task. Recently, several model-free continuous control algorithms were shown to learn successful policies without prior knowledge of the dynamics of the task. However, obtaining successful policies required thousands to millions of training episodes, limiting the applicability of these approaches to real hardware. We developed a training procedure that allows us to use a simple custom simulator to learn policies robust to the mismatch of simulation vs robot. In our experiments, we demonstrate that the policy learned in the simulator is able to pivot the object to the desired target angle on the real robot. We also show generalization to an object with different inertia, shape, mass and friction properties than those used during training. This result is a step towards making model-free reinforcement learning available for solving robotics tasks via pre-training in simulators that offer only an imprecise match to the real-world dynamics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/WRZCHVGB/Antonova et al. - 2017 - Reinforcement Learning for Pivoting Task.pdf;/Users/fracapuano/Zotero/storage/WJEJ2VGU/1703.html}
}

@misc{bekrisStateRobotMotion2024,
  title = {The {{State}} of {{Robot Motion Generation}}},
  author = {Bekris, Kostas E. and Doerr, Joe and Meng, Patrick and Tangirala, Sumanth},
  year = {2024},
  month = oct,
  number = {arXiv:2410.12172},
  eprint = {2410.12172},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.12172},
  urldate = {2025-08-26},
  abstract = {This paper reviews the large spectrum of methods for generating robot motion proposed over the 50 years of robotics research culminating in recent developments. It crosses the boundaries of methodologies, typically not surveyed together, from those that operate over explicit models to those that learn implicit ones. The paper discusses the current state-of-the-art as well as properties of varying methodologies, highlighting opportunities for integration.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/DMJJZFDZ/Bekris et al. - 2024 - The State of Robot Motion Generation.pdf;/Users/fracapuano/Zotero/storage/TL42IRAN/2410.html}
}

@article{burridgeSequentialCompositionDynamically1999b,
  title = {Sequential {{Composition}} of {{Dynamically Dexterous Robot Behaviors}}},
  author = {Burridge, R. R. and Rizzi, A. A. and Koditschek, D. E.},
  year = {1999},
  month = jun,
  journal = {The International Journal of Robotics Research},
  volume = {18},
  number = {6},
  pages = {534--555},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/02783649922066385},
  urldate = {2025-08-26},
  abstract = {We report on our efforts to develop a sequential robot controllercomposition technique in the context of dexterous ``batting'' maneuvers. A robot with a flat paddle is required to strike repeatedly at a thrown ball until the ball is brought to rest on the paddle at a specified location. The robot's reachable workspace is blocked by an obstacle that disconnects the free space formed when the ball and paddle remain in contact, forcing the machine to ``let go'' for a time to bring the ball to the desired state. The controller compositions we create guarantee that a ball introduced in the ``safe workspace'' remains there and is ultimately brought to the goal. We report on experimental results from an implementation of these formal composition methods, and present descriptive statistics characterizing the experiments.},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/TFZQ6EHJ/Burridge et al. - 1999 - Sequential Composition of Dynamically Dexterous Robot Behaviors.pdf}
}

@article{fujitaDevelopmentRobotsNuclear2020,
  title = {Development of {{Robots}} for {{Nuclear Power Plants}} and {{Their Application}} to {{New Fields}}},
  author = {Fujita, Jun and Soda, Daisuke and Murata, Chotaro and Tsuhari, Hiroyuki},
  year = {2020},
  volume = {57},
  number = {4},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/K349QTEG/Fujita et al. - 2020 - Development of Robots for Nuclear Power Plants and Their Application to New Fields.pdf}
}

@inproceedings{griffinWalkingStabilizationUsing2017,
  title = {Walking {{Stabilization Using Step Timing}} and {{Location Adjustment}} on the {{Humanoid Robot}}, {{Atlas}}},
  booktitle = {2017 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Griffin, Robert J. and Wiedebach, Georg and Bertrand, Sylvain and Leonessa, Alexander and Pratt, Jerry},
  year = {2017},
  month = sep,
  eprint = {1703.00477},
  primaryclass = {cs},
  pages = {667--673},
  doi = {10.1109/IROS.2017.8202223},
  urldate = {2025-08-26},
  abstract = {While humans are highly capable of recovering from external disturbances and uncertainties that result in large tracking errors, humanoid robots have yet to reliably mimic this level of robustness. Essential to this is the ability to combine traditional "ankle strategy" balancing with step timing and location adjustment techniques. In doing so, the robot is able to step quickly to the necessary location to continue walking. In this work, we present both a new swing speed up algorithm to adjust the step timing, allowing the robot to set the foot down more quickly to recover from errors in the direction of the current capture point dynamics, and a new algorithm to adjust the desired footstep, expanding the base of support to utilize the center of pressure (CoP)-based ankle strategy for balance. We then utilize the desired centroidal moment pivot (CMP) to calculate the momentum rate of change for our inverse-dynamics based whole-body controller. We present simulation and experimental results using this work, and discuss performance limitations and potential improvements.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/SSNAZ6U4/Griffin et al. - 2017 - Walking Stabilization Using Step Timing and Location Adjustment on the Humanoid Robot, Atlas.pdf;/Users/fracapuano/Zotero/storage/VP885PA9/1703.html}
}

@misc{hansenTemporalDifferenceLearning2022,
  title = {Temporal {{Difference Learning}} for {{Model Predictive Control}}},
  author = {Hansen, Nicklas and Wang, Xiaolong and Su, Hao},
  year = {2022},
  month = jul,
  number = {arXiv:2203.04955},
  eprint = {2203.04955},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.04955},
  urldate = {2025-08-25},
  abstract = {Data-driven model predictive control has two key advantages over model-free methods: a potential for improved sample efficiency through model learning, and better performance as computational budget for planning increases. However, it is both costly to plan over long horizons and challenging to obtain an accurate model of the environment. In this work, we combine the strengths of model-free and model-based methods. We use a learned task-oriented latent dynamics model for local trajectory optimization over a short horizon, and use a learned terminal value function to estimate long-term return, both of which are learned jointly by temporal difference learning. Our method, TD-MPC, achieves superior sample efficiency and asymptotic performance over prior work on both state and image-based continuous control tasks from DMControl and Meta-World. Code and video results are available at https://nicklashansen.github.io/td-mpc.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/TZF8LCDG/Hansen et al. - 2022 - Temporal Difference Learning for Model Predictive Control.pdf;/Users/fracapuano/Zotero/storage/WU2WWWQE/2203.html}
}

@misc{jiDribbleBotDynamicLegged2023,
  title = {{{DribbleBot}}: {{Dynamic Legged Manipulation}} in the {{Wild}}},
  shorttitle = {{{DribbleBot}}},
  author = {Ji, Yandong and Margolis, Gabriel B. and Agrawal, Pulkit},
  year = {2023},
  month = apr,
  number = {arXiv:2304.01159},
  eprint = {2304.01159},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.01159},
  urldate = {2025-08-26},
  abstract = {DribbleBot (Dexterous Ball Manipulation with a Legged Robot) is a legged robotic system that can dribble a soccer ball under the same real-world conditions as humans (i.e., in-the-wild). We adopt the paradigm of training policies in simulation using reinforcement learning and transferring them into the real world. We overcome critical challenges of accounting for variable ball motion dynamics on different terrains and perceiving the ball using body-mounted cameras under the constraints of onboard computing. Our results provide evidence that current quadruped platforms are well-suited for studying dynamic whole-body control problems involving simultaneous locomotion and manipulation directly from sensory observations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/ABSRE4C4/Ji et al. - 2023 - DribbleBot Dynamic Legged Manipulation in the Wild.pdf;/Users/fracapuano/Zotero/storage/ADI4QNCY/2304.html}
}

@article{khatibRealTimeObstancleAvoidance1986,
  title = {Real-{{Time Obstancle Avoidance}} for {{Manipulators}} and {{Mobile Robots}}},
  author = {Khatib, Oussama},
  year = {1986},
  journal = {The International Journal of Robotics Research},
  volume = {5}
}

@article{koberReinforcementLearningRobotics,
  title = {Reinforcement {{Learning}} in {{Robotics}}: {{A Survey}}},
  author = {Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/72PRHGKL/Kober et al. - Reinforcement Learning in Robotics A Survey.pdf}
}

@article{leeLearningQuadrupedalLocomotion2020,
  title = {Learning {{Quadrupedal Locomotion}} over {{Challenging Terrain}}},
  author = {Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  year = {2020},
  month = oct,
  journal = {Science Robotics},
  volume = {5},
  number = {47},
  eprint = {2010.11251},
  primaryclass = {cs},
  pages = {eabc5986},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.abc5986},
  urldate = {2025-08-26},
  abstract = {Some of the most challenging environments on our planet are accessible to quadrupedal animals but remain out of reach for autonomous machines. Legged locomotion can dramatically expand the operational domains of robotics. However, conventional controllers for legged locomotion are based on elaborate state machines that explicitly trigger the execution of motion primitives and reflexes. These designs have escalated in complexity while falling short of the generality and robustness of animal locomotion. Here we present a radically robust controller for legged locomotion in challenging natural environments. We present a novel solution to incorporating proprioceptive feedback in locomotion control and demonstrate remarkable zero-shot generalization from simulation to natural environments. The controller is trained by reinforcement learning in simulation. It is based on a neural network that acts on a stream of proprioceptive signals. The trained controller has taken two generations of quadrupedal ANYmal robots to a variety of natural environments that are beyond the reach of prior published work in legged locomotion. The controller retains its robustness under conditions that have never been encountered during training: deformable terrain such as mud and snow, dynamic footholds such as rubble, and overground impediments such as thick vegetation and gushing water. The presented work opens new frontiers for robotics and indicates that radical robustness in natural environments can be achieved by training in much simpler domains.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/fracapuano/Zotero/storage/8B9EF2CE/Lee et al. - 2020 - Learning Quadrupedal Locomotion over Challenging Terrain.pdf}
}

@book{lynchModernRoboticsMechanics2017,
  title = {Modern {{Robotics}}: {{Mechanics}}, {{Planning}}, and {{Control}}},
  shorttitle = {Modern {{Robotics}}},
  author = {Lynch, Kevin M. and Park, Frank C.},
  year = {2017},
  month = may,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781316661239},
  urldate = {2025-08-25},
  abstract = {This introduction to robotics offers a distinct and unified perspective of the mechanics, planning and control of robots. Ideal for self-learning, or for courses, as it assumes only freshman-level physics, ordinary differential equations, linear algebra and a little bit of computing background. Modern Robotics presents the state-of-the-art, screw-theoretic techniques capturing the most salient physical features of a robot in an intuitive geometrical way. With numerous exercises at the end of each chapter, accompanying software written to reinforce the concepts in the book and video lectures aimed at changing the classroom experience, this is the go-to textbook for learning about this fascinating subject.},
  copyright = {https://www.cambridge.org/core/terms},
  isbn = {978-1-316-66123-9 978-1-107-15630-2 978-1-316-60984-2},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/S9E6NIQ8/Lynch and Park - 2017 - Modern Robotics Mechanics, Planning, and Control.pdf}
}

@misc{margolisRapidLocomotionReinforcement2022,
  title = {Rapid {{Locomotion}} via {{Reinforcement Learning}}},
  author = {Margolis, Gabriel B. and Yang, Ge and Paigwar, Kartik and Chen, Tao and Agrawal, Pulkit},
  year = {2022},
  month = may,
  number = {arXiv:2205.02824},
  eprint = {2205.02824},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.02824},
  urldate = {2025-08-26},
  abstract = {Agile maneuvers such as sprinting and high-speed turning in the wild are challenging for legged robots. We present an end-to-end learned controller that achieves record agility for the MIT Mini Cheetah, sustaining speeds up to 3.9 m/s. This system runs and turns fast on natural terrains like grass, ice, and gravel and responds robustly to disturbances. Our controller is a neural network trained in simulation via reinforcement learning and transferred to the real world. The two key components are (i) an adaptive curriculum on velocity commands and (ii) an online system identification strategy for sim-to-real transfer leveraged from prior work. Videos of the robot's behaviors are available at: https://agility.csail.mit.edu/},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/URXYM9ZM/Margolis et al. - 2022 - Rapid Locomotion via Reinforcement Learning.pdf;/Users/fracapuano/Zotero/storage/S7PRP8ZT/2205.html}
}

@article{mooreRobotsNuclearPower,
  title = {Robots for Nuclear Power Plants},
  author = {Moore, Taylor},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/IMLZMTF3/Moore - Robots for nuclear power plants.pdf}
}

@misc{nvidiaGR00TN1Open2025,
  title = {{{GR00T N1}}: {{An Open Foundation Model}} for {{Generalist Humanoid Robots}}},
  shorttitle = {{{GR00T N1}}},
  author = {NVIDIA and Bjorck, Johan and Casta{\~n}eda, Fernando and Cherniadev, Nikita and Da, Xingye and Ding, Runyu and Fan, Linxi "Jim" and Fang, Yu and Fox, Dieter and Hu, Fengyuan and Huang, Spencer and Jang, Joel and Jiang, Zhenyu and Kautz, Jan and Kundalia, Kaushil and Lao, Lawrence and Li, Zhiqi and Lin, Zongyu and Lin, Kevin and Liu, Guilin and Llontop, Edith and Magne, Loic and Mandlekar, Ajay and Narayan, Avnish and Nasiriany, Soroush and Reed, Scott and Tan, You Liang and Wang, Guanzhi and Wang, Zu and Wang, Jing and Wang, Qi and Xiang, Jiannan and Xie, Yuqi and Xu, Yinzhen and Xu, Zhenjia and Ye, Seonghyeon and Yu, Zhiding and Zhang, Ao and Zhang, Hao and Zhao, Yizhou and Zheng, Ruijie and Zhu, Yuke},
  year = {2025},
  month = mar,
  number = {arXiv:2503.14734},
  eprint = {2503.14734},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.14734},
  urldate = {2025-08-26},
  abstract = {General-purpose robots need a versatile body and an intelligent mind. Recent advancements in humanoid robots have shown great promise as a hardware platform for building generalist autonomy in the human world. A robot foundation model, trained on massive and diverse data sources, is essential for enabling the robots to reason about novel situations, robustly handle real-world variability, and rapidly learn new tasks. To this end, we introduce GR00T N1, an open foundation model for humanoid robots. GR00T N1 is a Vision-Language-Action (VLA) model with a dual-system architecture. The vision-language module (System 2) interprets the environment through vision and language instructions. The subsequent diffusion transformer module (System 1) generates fluid motor actions in real time. Both modules are tightly coupled and jointly trained end-to-end. We train GR00T N1 with a heterogeneous mixture of real-robot trajectories, human videos, and synthetically generated datasets. We show that our generalist robot model GR00T N1 outperforms the state-of-the-art imitation learning baselines on standard simulation benchmarks across multiple robot embodiments. Furthermore, we deploy our model on the Fourier GR-1 humanoid robot for language-conditioned bimanual manipulation tasks, achieving strong performance with high data efficiency.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/BDNSKFA6/NVIDIA et al. - 2025 - GR00T N1 An Open Foundation Model for Generalist Humanoid Robots.pdf;/Users/fracapuano/Zotero/storage/FENU9PQR/2503.html}
}

@misc{openaiSolvingRubiksCube2019,
  title = {Solving {{Rubik}}'s {{Cube}} with a {{Robot Hand}}},
  author = {OpenAI and Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and Schneider, Jonas and Tezak, Nikolas and Tworek, Jerry and Welinder, Peter and Weng, Lilian and Yuan, Qiming and Zaremba, Wojciech and Zhang, Lei},
  year = {2019},
  month = oct,
  number = {arXiv:1910.07113},
  eprint = {1910.07113},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1910.07113},
  urldate = {2025-08-26},
  abstract = {We demonstrate that models trained only in simulation can be used to solve a manipulation problem of unprecedented complexity on a real robot. This is made possible by two key components: a novel algorithm, which we call automatic domain randomization (ADR) and a robot platform built for machine learning. ADR automatically generates a distribution over randomized environments of ever-increasing difficulty. Control policies and vision state estimators trained with ADR exhibit vastly improved sim2real transfer. For control policies, memory-augmented models trained on an ADR-generated distribution of environments show clear signs of emergent meta-learning at test time. The combination of ADR with our custom robot platform allows us to solve a Rubik's cube with a humanoid robot hand, which involves both control and state estimation problems. Videos summarizing our results are available: https://openai.com/blog/solving-rubiks-cube/},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  file = {/Users/fracapuano/Zotero/storage/5HNZLG9D/OpenAI et al. - 2019 - Solving Rubik's Cube with a Robot Hand.pdf;/Users/fracapuano/Zotero/storage/WSM7BJ4I/1910.html}
}

@misc{sannemanStateIndustrialRobotics2020,
  title = {The {{State}} of {{Industrial Robotics}}: {{Emerging Technologies}}, {{Challenges}}, and {{Key Research Directions}}},
  shorttitle = {The {{State}} of {{Industrial Robotics}}},
  author = {Sanneman, Lindsay and Fourie, Christopher and Shah, Julie A.},
  year = {2020},
  month = oct,
  number = {arXiv:2010.14537},
  eprint = {2010.14537},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2010.14537},
  urldate = {2025-08-26},
  abstract = {Robotics and related technologies are central to the ongoing digitization and advancement of manufacturing. In recent years, a variety of strategic initiatives around the world including "Industry 4.0", introduced in Germany in 2011 have aimed to improve and connect manufacturing technologies in order to optimize production processes. In this work, we study the changing technological landscape of robotics and "internet-of-things" (IoT)-based connective technologies over the last 7-10 years in the wake of Industry 4.0. We interviewed key players within the European robotics ecosystem, including robotics manufacturers and integrators, original equipment manufacturers (OEMs), and applied industrial research institutions and synthesize our findings in this paper. We first detail the state-of-the-art robotics and IoT technologies we observed and that the companies discussed during our interviews. We then describe the processes the companies follow when deciding whether and how to integrate new technologies, the challenges they face when integrating these technologies, and some immediate future technological avenues they are exploring in robotics and IoT. Finally, based on our findings, we highlight key research directions for the robotics community that can enable improved capabilities in the context of manufacturing.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/8ETI44WZ/Sanneman et al. - 2020 - The State of Industrial Robotics Emerging Technologies, Challenges, and Key Research Directions.pdf;/Users/fracapuano/Zotero/storage/Y37S4WE2/2010.html}
}

@book{sicilianoSpringerHandbookRobotics2016,
  title = {Springer {{Handbook}} of {{Robotics}}},
  editor = {Siciliano, Bruno and Khatib, Oussama},
  year = {2016},
  series = {Springer {{Handbooks}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-32552-1},
  urldate = {2025-08-26},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-319-32550-7 978-3-319-32552-1},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/JHG94GYG/Siciliano and Khatib - 2016 - Springer Handbook of Robotics.pdf}
}

@book{tedrakeUnderactuatedRoboticsAlgorithms,
  title = {Underactuated {{Robotics}}: {{Algorithms}} for {{Walking}}, {{Running}}, {{Swimming}}, {{Flying}}, and {{Manipulation}}},
  author = {Tedrake, Russ}
}

@article{thrunPROBABILISTICROBOTICS,
  title = {{{PROBABILISTIC ROBOTICS}}},
  author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
  langid = {english},
  file = {/Users/fracapuano/Zotero/storage/UKNC34V7/Thrun et al. - PROBABILISTIC ROBOTICS.pdf}
}

@misc{zhangWoCoCoLearningWholeBody2024,
  title = {{{WoCoCo}}: {{Learning Whole-Body Humanoid Control}} with {{Sequential Contacts}}},
  shorttitle = {{{WoCoCo}}},
  author = {Zhang, Chong and Xiao, Wenli and He, Tairan and Shi, Guanya},
  year = {2024},
  month = nov,
  number = {arXiv:2406.06005},
  eprint = {2406.06005},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.06005},
  urldate = {2025-08-26},
  abstract = {Humanoid activities involving sequential contacts are crucial for complex robotic interactions and operations in the real world and are traditionally solved by model-based motion planning, which is time-consuming and often relies on simplified dynamics models. Although model-free reinforcement learning (RL) has become a powerful tool for versatile and robust whole-body humanoid control, it still requires tedious task-specific tuning and state machine design and suffers from long-horizon exploration issues in tasks involving contact sequences. In this work, we propose WoCoCo (Whole-Body Control with Sequential Contacts), a unified framework to learn whole-body humanoid control with sequential contacts by naturally decomposing the tasks into separate contact stages. Such decomposition facilitates simple and general policy learning pipelines through task-agnostic reward and sim-to-real designs, requiring only one or two task-related terms to be specified for each task. We demonstrated that end-to-end RL-based controllers trained with WoCoCo enable four challenging whole-body humanoid tasks involving diverse contact sequences in the real world without any motion priors: 1) versatile parkour jumping, 2) box loco-manipulation, 3) dynamic clap-and-tap dancing, and 4) cliffside climbing. We further show that WoCoCo is a general framework beyond humanoid by applying it in 22-DoF dinosaur robot loco-manipulation tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Graphics,Computer Science - Robotics,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control},
  file = {/Users/fracapuano/Zotero/storage/2SYII7A2/Zhang et al. - 2024 - WoCoCo Learning Whole-Body Humanoid Control with Sequential Contacts.pdf;/Users/fracapuano/Zotero/storage/C6ZJPZEV/2406.html}
}

@misc{zhaoLearningFineGrainedBimanual2023,
  title = {Learning {{Fine-Grained Bimanual Manipulation}} with {{Low-Cost Hardware}}},
  author = {Zhao, Tony Z. and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  year = {2023},
  month = apr,
  number = {arXiv:2304.13705},
  eprint = {2304.13705},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.13705},
  urldate = {2025-08-26},
  abstract = {Fine manipulation tasks, such as threading cable ties or slotting a battery, are notoriously difficult for robots because they require precision, careful coordination of contact forces, and closed-loop visual feedback. Performing these tasks typically requires high-end robots, accurate sensors, or careful calibration, which can be expensive and difficult to set up. Can learning enable low-cost and imprecise hardware to perform these fine manipulation tasks? We present a low-cost system that performs end-to-end imitation learning directly from real demonstrations, collected with a custom teleoperation interface. Imitation learning, however, presents its own challenges, particularly in high-precision domains: errors in the policy can compound over time, and human demonstrations can be non-stationary. To address these challenges, we develop a simple yet novel algorithm, Action Chunking with Transformers (ACT), which learns a generative model over action sequences. ACT allows the robot to learn 6 difficult tasks in the real world, such as opening a translucent condiment cup and slotting a battery with 80-90\% success, with only 10 minutes worth of demonstrations. Project website: https://tonyzhaozh.github.io/aloha/},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/Users/fracapuano/Zotero/storage/4P7GCF3I/Zhao et al. - 2023 - Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware.pdf;/Users/fracapuano/Zotero/storage/3BC9S3Z2/2304.html}
}

@misc{zhongPracticalBlockwiseNeural2018,
  title = {Practical {{Block-wise Neural Network Architecture Generation}}},
  author = {Zhong, Zhao and Yan, Junjie and Wu, Wei and Shao, Jing and Liu, Cheng-Lin},
  year = {2018},
  month = may,
  number = {arXiv:1708.05552},
  eprint = {1708.05552},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-05-05},
  abstract = {Convolutional neural networks have gained a remarkable success in computer vision. However, most usable network architectures are hand-crafted and usually require expertise and elaborate design. In this paper, we provide a block-wise network generation pipeline called BlockQNN which automatically builds high-performance networks using the Q-Learning paradigm with epsilon-greedy exploration strategy. The optimal network block is constructed by the learning agent which is trained sequentially to choose component layers. We stack the block to construct the whole auto-generated network. To accelerate the generation process, we also propose a distributed asynchronous framework and an early stop strategy. The block-wise generation brings unique advantages: (1) it performs competitive results in comparison to the hand-crafted state-of-the-art networks on image classification, additionally, the best network generated by BlockQNN achieves 3.54\% top-1 error rate on CIFAR-10 which beats all existing auto-generate networks. (2) in the meanwhile, it offers tremendous reduction of the search space in designing networks which only spends 3 days with 32 GPUs, and (3) moreover, it has strong generalizability that the network built on CIFAR also performs well on a larger-scale ImageNet dataset.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/fracapuano/Zotero/storage/7ZJWPCRW/Zhong et al. - 2018 - Practical Block-wise Neural Network Architecture G.pdf;/Users/fracapuano/Zotero/storage/ZI2R395F/Zhong et al. - 2018 - Practical Block-wise Neural Network Architecture G.html}
}
